#include "vg_define.h"
#include "culling.h"
#include "wave.h"

shared uvec4 SharedCandidateNodeBatch[BVH_MAX_GROUP_BATCH_SIZE];
shared uint SharedNodeBatchReadOffset;
shared uint SharedNodeReadyMask;
shared uint SharedNodeCount;
shared uint SharedClusterReadOffset;
shared uint SharedClusterReadNum;

#define DONT_USE_SHARED_NODE_BATCH 0
#define EMIT_CLUSTER_EACH_THREAD 1

void ProcessClusterBatch(uint groupIndex, uint batchStart, uint batchSize)
{
	uint batchIndex = batchStart + groupIndex;	
#if INSTANCE_CULL_MODE == INSTANCE_CULL_POST
	batchStart += MAX_CANDIDATE_CLUSTER;
	batchIndex += MAX_CANDIDATE_CLUSTER;
#endif
	if (groupIndex < batchSize)
	{
		CandidateCluster candidateCluster = UnpackCandidateCluster(CandidateClusterBatch[batchIndex]);
		uint instanceId = candidateCluster.instanceId;

		ClusterBatchStruct clusterBatch;
		GetClusterData(candidateCluster, clusterBatch);

		mat4 localToWorld = InstanceData[instanceId].transform;

		vec3 boundCenter = clusterBatch.lodBoundCenterError.xyz;
		float localError = (clusterBatch.leaf == 0) ? clusterBatch.lodBoundCenterError.w : 0;
		vec3 boundHalfExtend = clusterBatch.lodBoundHalfExtendRadius.xyz;
		float boundRadius = clusterBatch.lodBoundHalfExtendRadius.w;

		FrustumCullData cullData = BoxCullFrustumGeneral(boundCenter, boundHalfExtend, localToWorld, worldToClip, true, false);

#if CULL_CLUSTER_ALONG_BVH
		if (cullData.bIsVisible)
		{
#if USE_INSTANCE_CENTER_CULL
			cullData.bIsVisible = SmallEnoughToDraw(localToWorld, worldToView, vec3(0, 0, 0), boundRadius, localError);
#else
			cullData.bIsVisible = SmallEnoughToDraw(localToWorld, worldToView, boundCenter, boundRadius, localError);
#endif
		}
#else
		if (cullData.bIsVisible)
		{
			vec3 parentBoundCenter = clusterBatch.parentBoundCenterError.xyz;
			float parentError = clusterBatch.parentBoundCenterError.w;
			float parentBoundRadius = clusterBatch.parentBoundHalfExtendRadius.w;
#if USE_INSTANCE_CENTER_CULL
			cullData.bIsVisible = FitToDraw(localToWorld, worldToView, vec3(0, 0, 0), boundRadius, localError, vec3(0, 0, 0), parentBoundRadius, parentError);
#else
			cullData.bIsVisible = FitToDraw(localToWorld, worldToView, boundCenter, boundRadius, localError, parentBoundCenter, parentBoundRadius, parentError);
#endif
		}
#endif

#if INSTANCE_CULL_MODE == INSTANCE_CULL_MAIN || INSTANCE_CULL_MODE == INSTANCE_CULL_POST
		if (cullData.bIsVisible)
		{
			ivec2 hzbSize = textureSize(hiZTex, 0);
			ScreenRect rect = GetScreenRect(ivec4(0, 0, hzbSize * 2), cullData, 4);
			cullData.bIsVisible = IsVisibleHZB(rect, hzbSize, true);
		}
#if INSTANCE_CULL_MODE == INSTANCE_CULL_MAIN
		if (!cullData.bIsVisible)
		{
			uint clusterWriteOffset = 0;
			WAVE_INTERLOCK_ADD(QueueState[QUEUE_STATE_POST_INDEX].clusterWriteOffset, 1, clusterWriteOffset);
			if (clusterWriteOffset < MAX_CANDIDATE_CLUSTER)
			{
				clusterWriteOffset += MAX_CANDIDATE_CLUSTER;
				StoreCandidateCluster(clusterWriteOffset, candidateCluster);
			}
		}
#endif
#endif
		if (cullData.bIsVisible)
		{
			uint clusterWriteOffset = 0;
			WAVE_INTERLOCK_ADD(QueueState[QUEUE_STATE_INDEX].visibleClusterNum, 1, clusterWriteOffset);
			if (clusterWriteOffset < MAX_CANDIDATE_CLUSTER)
			{
				StoreSelectedCluster(clusterWriteOffset, candidateCluster);
				// ExtraDebugInfo[clusterWriteOffset] = GetProjectScale(localToWorld, worldToView, boundCenter, boundRadius).x;
			}
		}
		CandidateClusterBatch[batchIndex] = uvec4(0xFFFFFFFF);
	}
}

void ProcessNodeBatch(uint groupIndex, uint batchStart, uint batchSize)
{
	uint localIndex = groupIndex / BVH_MAX_NODES;
	if (localIndex < batchSize)
	{
		uint childIndex = groupIndex & BVH_NODE_MASK;
		uint batchIndex = batchStart + localIndex;
#if INSTANCE_CULL_MODE == INSTANCE_CULL_POST
		batchIndex += MAX_CANDIDATE_NODE;
#endif
#if DONT_USE_SHARED_NODE_BATCH
		CandidateNode nodeBatch = UnpackCandidateNode(CandidateNodeBatch[batchIndex]);
#else
		CandidateNode nodeBatch = UnpackCandidateNode(SharedCandidateNodeBatch[localIndex]);
#endif

		uint instanceId = nodeBatch.instanceId;
		uint resourceIndex = InstanceData[instanceId].resourceIndex;

		ClusterHierarchyStruct hierarchy;
		GetHierarchyData(nodeBatch, hierarchy);

		uint isLeaf = hierarchy.isLeaf;
		mat4 localToWorld = InstanceData[instanceId].transform;

		if (isLeaf == 0)
		{
			uint nodeIndex = hierarchy.children[childIndex];
			if (nodeIndex != INVALID_INDEX)
			{
				CandidateNode childBatch;
				childBatch.instanceId = instanceId;
				childBatch.nodeIndex = nodeIndex;

				ClusterHierarchyStruct childHierarchy;
				GetHierarchyData(childBatch, childHierarchy);

				vec3 boundCenter = childHierarchy.lodBoundCenterError.xyz;
				float maxParentError = childHierarchy.lodBoundCenterError.w;
				vec3 boundHalfExtend = childHierarchy.lodBoundHalfExtendRadius.xyz;
				float radius = childHierarchy.lodBoundHalfExtendRadius.w;

				FrustumCullData cullData = BoxCullFrustumGeneral(boundCenter, boundHalfExtend, localToWorld, worldToClip, true, false);

#if CULL_CLUSTER_ALONG_BVH
				if (cullData.bIsVisible)
				{
#if USE_INSTANCE_CENTER_CULL
					cullData.bIsVisible = ShouldVisitChild(localToWorld, worldToView, vec3(0, 0, 0), radius, maxParentError);
#else
					cullData.bIsVisible = ShouldVisitChild(localToWorld, worldToView, boundCenter, radius, maxParentError);
#endif // USE_INSTANCE_CENTER_CULL
				}
#endif // CULL_CLUSTER_ALONG_BVH

#if INSTANCE_CULL_MODE == INSTANCE_CULL_MAIN || INSTANCE_CULL_MODE == INSTANCE_CULL_POST
				if (cullData.bIsVisible)
				{
					ivec2 hzbSize = textureSize(hiZTex, 0);
					ScreenRect rect = GetScreenRect(ivec4(0, 0, hzbSize * 2), cullData, 4);
					cullData.bIsVisible = IsVisibleHZB(rect, hzbSize, true);
#if INSTANCE_CULL_MODE == INSTANCE_CULL_MAIN
					if (!cullData.bIsVisible)
					{
						uint nodeWriteOffset = 0;
						WAVE_INTERLOCK_ADD_ONLY(QueueState[QUEUE_STATE_POST_INDEX].nodeCount, 1);
						WAVE_INTERLOCK_ADD(QueueState[QUEUE_STATE_POST_INDEX].nodeWriteOffset, 1, nodeWriteOffset);
						if (nodeWriteOffset < MAX_CANDIDATE_NODE)
						{
							nodeWriteOffset += MAX_CANDIDATE_NODE;
							StoreCandidateNode(nodeWriteOffset, childBatch);
						}
					}
#endif // INSTANCE_CULL_MODE == INSTANCE_CULL_MAIN
				}
#endif
				if (cullData.bIsVisible)
				{
					uint nodeWriteOffset = 0;
					WAVE_INTERLOCK_ADD_ONLY(QueueState[QUEUE_STATE_INDEX].nodeCount, 1);
					WAVE_INTERLOCK_ADD(QueueState[QUEUE_STATE_INDEX].nodeWriteOffset, 1, nodeWriteOffset);
					if (nodeWriteOffset < MAX_CANDIDATE_NODE)
					{
#if INSTANCE_CULL_MODE == INSTANCE_CULL_POST
						nodeWriteOffset += MAX_CANDIDATE_NODE;
#endif
						StoreCandidateNode(nodeWriteOffset, childBatch);
					}
				}
			}
		}
		// Leaf
		else
		{
#if EMIT_CLUSTER_EACH_THREAD
			uint clusterNumPerChild = hierarchy.clusterNum / BVH_MAX_NODES;
			uint clusterNumPerChildRest = hierarchy.clusterNum & BVH_NODE_MASK;

			uint clusterStart = hierarchy.clusterStart + childIndex * clusterNumPerChild + uint(childIndex != 0) * clusterNumPerChildRest;
			uint clusterNum = clusterNumPerChild + uint(childIndex == 0) * clusterNumPerChildRest;
#else
			uint clusterStart = hierarchy.clusterStart;
			uint clusterNum = 0;
			if (childIndex == 0)
			{
				clusterNum = hierarchy.clusterNum;
			}
#endif
			clusterNum = (hierarchy.clusterPageIndex != INVALID_INDEX) ? clusterNum : 0;
			if (clusterNum > 0)
			{
				uint clusterBaseWriteOffset = 0;
				WAVE_INTERLOCK_ADD(QueueState[QUEUE_STATE_INDEX].clusterWriteOffset, clusterNum, clusterBaseWriteOffset);

				for (uint i = 0; i < clusterNum; ++i)
				{
					uint clusterWriteOffset = clusterBaseWriteOffset + i;
					if (clusterWriteOffset >= MAX_CANDIDATE_CLUSTER)
					{
						break;
					}
#if INSTANCE_CULL_MODE == INSTANCE_CULL_POST
					clusterWriteOffset += MAX_CANDIDATE_CLUSTER;
#endif
					CandidateCluster candidateCluster;
					candidateCluster.instanceId = instanceId;
					candidateCluster.pageIndex = hierarchy.clusterPageIndex;
					candidateCluster.clusterIndex = clusterStart + i;
					StoreCandidateCluster(clusterWriteOffset, candidateCluster);
				}
			}
		}
	}

	barrier();
	if (groupIndex == 0)
	{
		WAVE_INTERLOCK_ADD_ONLY(QueueState[QUEUE_STATE_INDEX].nodeCount, -batchSize);
	}
}

#if defined(PERSISTENT_CULL)

layout(local_size_x = VG_GROUP_SIZE, local_size_y = 1, local_size_z = 1) in;
void main()
{
	uint groupIndex = gl_LocalInvocationID.x;

	uint nodeProcessOffset = BVH_MAX_GROUP_BATCH_SIZE;
	uint nodeReadOffset = 0;

	bool bProcessNode = true;
	bool bProcessCluster = true;
	uint loopCounter = 0;
	const uint maxLoopCount = 10000;

	SharedClusterReadOffset = 0xFFFFFFFF;
	SharedClusterReadNum = 0;

	while (bProcessNode || bProcessCluster)
	{
		SharedNodeReadyMask = 0;
		barrier();

		if (nodeProcessOffset == BVH_MAX_GROUP_BATCH_SIZE)
		{
			if (groupIndex == 0)
			{
				WAVE_INTERLOCK_ADD(QueueState[QUEUE_STATE_INDEX].nodeReadOffset, BVH_MAX_GROUP_BATCH_SIZE, SharedNodeBatchReadOffset);
			}
			barrier();
			nodeProcessOffset = 0;
			nodeReadOffset = SharedNodeBatchReadOffset;
		}

		uint nodeBatchStart = nodeReadOffset + nodeProcessOffset;
		uint nodeBatchIndex = nodeBatchStart + groupIndex;
		bProcessNode = nodeBatchIndex < MAX_CANDIDATE_NODE;

		if (bProcessNode)
		{
#if INSTANCE_CULL_MODE == INSTANCE_CULL_POST
			nodeBatchStart += MAX_CANDIDATE_NODE;
			nodeBatchIndex += MAX_CANDIDATE_NODE;
#endif
			bool bNodeReady = bProcessNode && (nodeProcessOffset + groupIndex < BVH_MAX_GROUP_BATCH_SIZE);
			if (bNodeReady)
			{
				bNodeReady = CandidateNodeBatch[nodeBatchIndex].x != 0xFFFFFFFF;
			}

			if (bNodeReady)
			{
				SharedCandidateNodeBatch[groupIndex] = CandidateNodeBatch[nodeBatchIndex];
				atomicOr(SharedNodeReadyMask, 1 << groupIndex);
			}
			barrier();

			uint nodeReadyMask = SharedNodeReadyMask;
			if ((nodeReadyMask & 1) == 1)
			{
				// Maybe the bNodeReady can be [0 1 1 1 0 1 1 1] in each thread
				// And nodeReadyMask is [01110111] and findLSB(~nodeReadyMask) is 3
				// However the bitCount(nodeReadyMask) is 6
				uint batchSize = findLSB(~nodeReadyMask); // bitCount(nodeReadyMask);
				ProcessNodeBatch(groupIndex, nodeBatchStart, batchSize);
				if (groupIndex < batchSize) // (bNodeReady)
				{
					CandidateNodeBatch[nodeBatchIndex] = uvec4(0xFFFFFFFF);
				}
				nodeProcessOffset += batchSize;
				continue;
			}
		}

		if (groupIndex == 0)
		{
			SharedNodeCount = QueueState[QUEUE_STATE_INDEX].nodeCount;
		}
		barrier();

		if (SharedNodeCount == 0)
		{
			bProcessNode = false;
		}

		if (groupIndex == 0 && SharedClusterReadOffset == 0xFFFFFFFF)
		{
			WAVE_INTERLOCK_ADD(QueueState[QUEUE_STATE_INDEX].clusterReadOffset, VG_GROUP_SIZE, SharedClusterReadOffset);
		}
		barrier();

		uint clusterReadOffset = SharedClusterReadOffset;
		uint clusterBatchStart = clusterReadOffset;
		uint clusterBatchIndex = clusterBatchStart + groupIndex;
		bProcessCluster = clusterBatchIndex < MAX_CANDIDATE_CLUSTER;

		if (bProcessCluster)
		{
#if INSTANCE_CULL_MODE == INSTANCE_CULL_POST
			bProcessCluster = CandidateClusterBatch[clusterBatchIndex + MAX_CANDIDATE_CLUSTER].x != 0xFFFFFFFF;
#else
			bProcessCluster = CandidateClusterBatch[clusterBatchIndex].x != 0xFFFFFFFF;
#endif
			if (bProcessCluster)
			{
				ProcessClusterBatch(0, clusterBatchIndex, 1);
				if (bProcessNode)
				{
					WAVE_INTERLOCK_ADD_ONLY(SharedClusterReadNum, 1);
				}
			}
		}

		barrier();
		if (!bProcessNode || SharedClusterReadNum == VG_GROUP_SIZE)
		{
			SharedClusterReadOffset = 0xFFFFFFFF;
			SharedClusterReadNum = 0;
		}

		// Protect from system crash...
		loopCounter += 1;
		if (loopCounter >= maxLoopCount)
		{
			break;
		}
	}
}

#elif defined(NODE_CULL)

layout(local_size_x = VG_GROUP_SIZE, local_size_y = 1, local_size_z = 1) in;
void main()
{
	uint groupID = gl_WorkGroupID.x;
	uint groupIndex = gl_LocalInvocationID.x;
	uint batchStart = QueueState[QUEUE_STATE_INDEX].nodeReadOffset + groupID * BVH_MAX_GROUP_BATCH_SIZE;
	uint batchSize = min(batchStart + BVH_MAX_GROUP_BATCH_SIZE, QueueState[QUEUE_STATE_INDEX].nodePrevWriteOffset) - batchStart;

	uint batchIndex = batchStart + groupIndex;
#if INSTANCE_CULL_MODE == INSTANCE_CULL_POST
	batchStart += MAX_CANDIDATE_NODE;
	batchIndex += MAX_CANDIDATE_NODE;
#endif

#if DONT_USE_SHARED_NODE_BATCH == 0
	if (groupIndex < batchSize)
	{
		SharedCandidateNodeBatch[groupIndex] = CandidateNodeBatch[batchIndex];
	}
	barrier();
#endif
	ProcessNodeBatch(groupIndex, batchStart, batchSize);
	if (groupIndex < batchSize)
	{
		CandidateNodeBatch[batchIndex] = uvec4(0xFFFFFFFF);
	}
}

#else

layout(local_size_x = VG_GROUP_SIZE, local_size_y = 1, local_size_z = 1) in;
void main()
{
	uint groupID = gl_WorkGroupID.x;
	uint groupIndex = gl_LocalInvocationID.x;

	uint batchStart = QueueState[QUEUE_STATE_INDEX].clusterReadOffset + groupID * VG_GROUP_SIZE;
	uint batchSize = min(batchStart + VG_GROUP_SIZE, QueueState[QUEUE_STATE_INDEX].clusterWriteOffset) - batchStart;

	if (groupIndex < batchSize)
	{
		ProcessClusterBatch(groupIndex, batchStart, batchSize);
	}
}

#endif